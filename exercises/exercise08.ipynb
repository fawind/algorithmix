{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1 (Lebkuchen sortieren)\n",
    "\n",
    "## a) Algorithmus\n",
    "\n",
    "1. Iteriere über die Lebkuchen absteigend nach ihrer Dicke sortiert. Für jeden dieser Lebkuchen $n$ führe die folgende Operation aus:\n",
    "  1. Drehe den Stapel bis einschließlich $n$. Dadurch befindet sich $n$ nun an oberster Stelle.\n",
    "  2. Drehe den Stapel nun bis einschließlich der Position, an die $n$ gehört. Sind wir z.B. beim dritt größten Lebkuchen, so drehen wir den Stapel bis einschließlich der dritt-untersten Position. Dadurch wird $n$ an seine rechtmäßige Position gesetzt.\n",
    "  \n",
    "Da jeder Lebkuchen maximal einmal an den Anfang des Stapels und dann an seine Position getauscht wird, haben wir pro Lebkuchen nur maximal $2$ Lebkuchenwendeoperationen. Für alle $n$ Lebkuchen erhalten wir also maximal $2n$ Lebkuchenwendeoperationen.\n",
    "\n",
    "## b) Verziehrte Lebkuchen\n",
    "\n",
    "Um zu garantieren, dass alle Lebkuchen mit der verziehrten Seite nach open liegen, reicht eine kleine Modifizierung des bisherigen Algorithmus aus **a)**.\n",
    "\n",
    "Nachdem der aktuelle Lebkuchen an die Spitze des Stapels getauscht wurde, wird dieser einmal zusätzlich gewendet, falls er mit der verzierten Seite nach oben liegt. Der Lebkuchen kann einzeln gewendet werden, da er der oberste Lebkuchen im Stapel ist. Dadurch ist sichergestellt, dass der Lebkuchen richtig orientiert ist, befor er im nächsten Zug an seine richtige Position gewendet wird. Da durch diese Wendeoperation der Lebkuchen noch einmal gedreht wird, liegt er sich anschließend mit der Verziehrung nach oben.\n",
    "\n",
    "Jeder Lebkuchen wird maximal dreimal gewendet. Einmal um den Lebkuchen an die Spitze des Stapels zu bekommen, einmal um die Vierziehrung auszurichten und einmal um den Lebkuchen an seine erwartete Position zu bekommen. Dadurch benötigen wir auch für alle $n$ Lebkuchen maximal $3n$ Lebkuchenwendeoperationen.\n",
    "\n",
    "## c) Verbesserter Algorithmus (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2 (Beaps und amortisierte Analyse)\n",
    "\n",
    "## a) Baue B(A)\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/7422050/34080125-7bc70f8e-e339-11e7-9488-5ff6a431d813.jpg\" width=\"400\" />\n",
    "\n",
    "## b) Laufzeit von BuildBeap\n",
    "\n",
    "Angenommen wir betreiben iterative Suchen nach dem Minimum in jedem Teilarray, ohne uns zusätzliche Informationen zu speichern, so muss jedes mal über das komplette Teilarray iteriert werden, um das Minimum zu finden. Für die Laufzeit des Algorithmus ist also entscheidend, wie sich die Größen der Teilarrays verändern.\n",
    "\n",
    "Angenommen wir befinden uns nun in einer Iterationen, in der wir das Teilarray $B$ mit größe $k$ als Input erhalten. Das finden des Minimums liegt nun in $\\Theta(k)$, da wir immer alle Elemente von $B$ anschauen müssen. Abhängig von der Position des Minimums, erhalten wir nun zwei unterschiedlich große Teilarrays für die nächste Iteration. Insgesamt gilt aber, dass die gesamtgröße der beiden Teilarrays immer genau $k-1$ beträgt, da lediglich das Minimum von $B$ in den nächsten Iterationen nicht mehr in Betracht gezogen wird. Daraus folgt, dass unabhängig von der Position des gefundenen Minimums und somit auch unabhängig von der Aufteilung der zwei neuen Teilarrays, der Algorithmus in den folgenden Iterationen nochmal über $k-1$ Elemente iterieren muss, um die nächsten Minima zu suchen. Diese $k-1$ Elemente können zwar auf zwei Teilarrays verteilt sein, jedoch ändert dies nichts an der insgesamten Anzahl an Schritten, um die Minima in beiden Teilarrays zu finden, welche $k-1$ ist.\n",
    "\n",
    "Insgesamt lässt sich also Festhalten, dass wir immer $n + (n-1) + (n-2) + (n-3) + ... + 1$ Schritte brauchen um alle Minima zu finden, unabhängig davon, wie unsere Teilarrays aufgespalten werden. Diese Laufzeit lässt sich mit der Dreieckssumme beschreiben: $\\sum_{k=1}^n k = \\frac{n (n+1)}{2}$. Sowohl die worst-case, also auch die Best-case Laufzeit liefen somit in $\\Theta(\\frac{n (n+1)}{2}) \\in O(n^2)$.\n",
    "\n",
    "**TODO:** Master-Theorem: $T(n) = 2 T(\\frac{n-1}{2}) + n$\n",
    "\n",
    "Best case log n weil beim Balancierten Baum der branching faktor größer ist und bei jedem Branchen ein zusätzliches Element wegfällt.\n",
    "\n",
    "## c) Korrektheit von BuildBeapIncremental\n",
    "\n",
    "## d) Laufzeit von BuildBeapIncremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3 (Beaps und Priority Queues)\n",
    "\n",
    "## a) Korrektheit von BeapSort\n",
    "\n",
    "Aus der Konstruktion von Beaps ergibt sich, dass an jeder Node das linke Kind das Minimum im folgenden linken Teilarray und das rechte Kind das Minimum in rechten Teilarray sein muss.\n",
    "\n",
    "Da dadurch die Wurzel von $T$ das globale Minimum sein muss, ist der Algorithmus in der initialen Iteration korrekt. Die Wurzel von $T$ wird an Stelle $A[0]$ eingefügt.\n",
    "\n",
    "Als nächstes werden die Kinder der Wurzel eingefügt. Trivialerweise gilt, dass das nächst größere Element entweder das Minimum im rechten oder linken Teilarray, sprich eines der beiden Kinder der Wurzel, sein muss.\n",
    "\n",
    "In der nächsten Iteration, wir nun das kleinere der beiden Kinder aus der Queue entfernt und dessen Kinder wieder eingefügt. Hierbei gilt, dass das nächst größere Element entweder das andere, alte Kind ist oder eines der beiden neu hinzugefügten Kinder sein muss. Dies gilt dadurch, dass diese Elemente die nächst größeren Elemente im linken oder rechten Teilarray sein müssen, da immer iterativ das nächste Minimum in den Beap eingefügt wurde.\n",
    "\n",
    "Dadurch ist garantiert, dass sich in jeder iteration der for-Schleife das nächst größere Element in der PriorityQueue befindet. Da die PriorityQueue die Nodes aufsteigend nach ihrem Schlüssel ausgibt, gibt `Q.ExtractMin()` in jeder Iteration das nächst größere Element aus. Dadurch können wir dieses einfach an die $i$-te Stelle von $A$ einfügen und erhalten nach allen Iterationen ein sortiertes Array.\n",
    "\n",
    "## b) Worst-case Laufzeit von BeapSort\n",
    "\n",
    "Wie zuvor gezeigt hat `BuildBeapIncremental` eine Laufzeit in $O(n)$. Zudem läuft die `for`-Schleife immer $n-1$ Schritte unabhängig von der Implementierung der PriorityQueue. Innerhalb der `for`-Schleife haben wir immer eine `ExtractMin` operation, sowie maximal zwei `Insert` operationen, da jeder Knoten maximal zwei Kinder hat. Somit liegt die Laufzeit also in $O(n + n * (\\text{ExtractMin} + 2 * \\text{Insert}))$. Interessant sind also die Kosten von `ExtractMin` und `Insert`.\n",
    "\n",
    "### i) Mit binären Min-Heap\n",
    "\n",
    "Bei einem binären Heap, liegen die worst-case Laufzeiten von `ExtractMin` und `Insert` in $O(\\log n)$. Insgesamt die somit die worst-case Laufzeit von `BeapSort` in $O(n + 3n \\log n) \\in O(n \\log n)$.\n",
    "\n",
    "### ii) Mit Hollow Heap\n",
    "\n",
    "Bei einem Hollow Heap liegen die Laufzeiten von `ExtractMin` in $O(\\log n)$ und von `Insert` in $O(1)$. Insgesamt ergibt sich somit eine Laufzeit von $O(n + n \\log n) \\in O(n \\log n)$. Unter Verwendung von Hollow Heaps ist `BeapSort` also um einen multplikativen Faktor von $3$ schneller als mit einem binären Heap.\n",
    "\n",
    "## c) Laufzeit bei Vorsortiertheit\n",
    "\n",
    "### i) Max elemente nach Entfernen von $a_i$\n",
    "\n",
    "**Pro Bergkette nur ein Element in Queue:**\n",
    "\n",
    "1) Alle Elemente in der PQ sind Bergketten zu $a_i$. Da $a_i$ das Element ist, das aus der PQ entfernt ist, müssen alle anderen Elemente größer als $a_i$ sein und sind damit Bergketten in Bezug auf $a_i$.\n",
    "2) Alle Bergketten in der PQ haben nur ein Element.\n",
    "  * Aus Konstruktion von Beap folgt, dass jede Node die beiden Teilarrays des linken und rechten Subbaumes aufteilt. Dadurch können zwei Elemente jeweils aus dem linken und rechten Subbaum von $a_i$ nie zusammen Teil einer Bergkette sein, da die Sequenz mindestens von $a_i$ aufgebrochen wird.\n",
    "  * Um eine Bergkette zu erhalten, die länger als ein Element lang ist, brauche ich sowohl Elemente von meinen Subtrees, als auch von der jeweiligen Wurzel. Da im Algorithmus aber in jeder Iteration nur Kinder hinzugefügt wurden, wenn ihr Vater aus der Queue entfernt wurde, kann es nie Bergketten mit mehr als einem Element geben.\n",
    "\n",
    "## d) Best-case und worst-case Laufzeit mit binären Heaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
